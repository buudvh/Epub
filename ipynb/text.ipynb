{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tách VietPharse nhiều nghĩa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã phân tách thành công!\n"
     ]
    }
   ],
   "source": [
    "# Đọc nội dung từ file txt\n",
    "with open('VietPhrase_20250110_111217.txt', 'r', encoding='utf-8') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Danh sách chứa các dòng có dấu ¦ và không có dấu ¦\n",
    "lines_with_pipe = []\n",
    "lines_without_pipe = []\n",
    "\n",
    "# Phân loại các dòng\n",
    "for line in lines:\n",
    "    if '¦' in line:\n",
    "        lines_with_pipe.append(line)\n",
    "    else:\n",
    "        lines_without_pipe.append(line)\n",
    "\n",
    "# Ghi vào file chứa dòng có dấu ¦\n",
    "with open('with_pipe.txt', 'w', encoding='utf-8') as file:\n",
    "    file.writelines(lines_with_pipe)\n",
    "\n",
    "# Ghi vào file chứa dòng không có dấu ¦\n",
    "with open('without_pipe.txt', 'w', encoding='utf-8') as file:\n",
    "    file.writelines(lines_without_pipe)\n",
    "\n",
    "print(\"Đã phân tách thành công!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tách các dòng có vế trái giống nhau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã phân tách các dòng theo yêu cầu!\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "input_path = './final/name.txt'\n",
    "output_path_group = './final/name_group.txt'\n",
    "output_path_other = './final/name_other.txt'\n",
    "\n",
    "# Đọc nội dung từ file txt\n",
    "with open(input_path, 'r', encoding='utf-8') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Sử dụng defaultdict để nhóm các dòng theo vế trái dấu \"=\"\n",
    "grouped_lines = defaultdict(list)\n",
    "other_lines = []\n",
    "wrong_lines = []\n",
    "\n",
    "# Phân loại các dòng\n",
    "for line in lines:\n",
    "    parts = line.strip().split('=')\n",
    "    if len(parts) == 2:\n",
    "        left, right = parts\n",
    "        grouped_lines[left].append(line)\n",
    "    else:\n",
    "        wrong_lines.append(line)\n",
    "\n",
    "# Ghi các dòng có vế trái giống nhau vào file\n",
    "with open(output_path_group, 'w', encoding='utf-8') as file:\n",
    "    for left, group in grouped_lines.items():\n",
    "        if len(group) > 1:  # Chỉ ghi các nhóm có vế trái giống nhau\n",
    "            file.writelines(group)\n",
    "        else:\n",
    "            other_lines = other_lines + group\n",
    "\n",
    "# Ghi các dòng không có vế trái giống nhau vào file\n",
    "with open(output_path_other, 'w', encoding='utf-8') as file:\n",
    "    file.writelines(other_lines)\n",
    "\n",
    "print(\"Đã phân tách các dòng theo yêu cầu!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loại bỏ dòng giống nhau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File đã được xử lý và lưu tại: ./final/without_pipe_group_v2.txt\n"
     ]
    }
   ],
   "source": [
    "input_file = \"./final/without_pipe_group.txt\"  # Đổi thành tên file của bạn\n",
    "output_file = \"./final/without_pipe_group_v2.txt\"\n",
    "\n",
    "# Đọc file và loại bỏ các dòng trùng lặp liên tiếp\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "unique_lines = []\n",
    "for i in range(len(lines)):\n",
    "    if i == 0 or lines[i] != lines[i - 1]:\n",
    "        unique_lines.append(lines[i])\n",
    "\n",
    "# Ghi các dòng không trùng lặp vào file mới\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.writelines(unique_lines)\n",
    "\n",
    "print(f\"File đã được xử lý và lưu tại: {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "input_path = './final/Name_20250110_164700.txt'\n",
    "output_path_group = './final/lowercase.txt'\n",
    "output_path_other = './final/uppercase.txt'\n",
    "\n",
    "\n",
    "def split_lines(input_file, lowercase_file, other_file):\n",
    "    with open(input_file, 'r', encoding='utf-8') as infile, open(lowercase_file, 'w', encoding='utf-8') as lower_out, open(other_file, 'w', encoding='utf-8') as other_out:\n",
    "        \n",
    "        for line in infile:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            \n",
    "            left, right = line.split('=', 1)\n",
    "            if right.islower():\n",
    "                lower_out.write(line + '\\n')\n",
    "            else:\n",
    "                other_out.write(line + '\\n')\n",
    "\n",
    "# Sử dụng hàm\n",
    "split_lines(input_path, output_path_group, output_path_other)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path_one = './final/4.9.6vp mrbeo.txt'\n",
    "input_path_two = './final/vpkhongloc.txt'\n",
    "output_path = './final/vpkhongloc_v2.txt'\n",
    "\n",
    "def read_file_to_dict(filename):\n",
    "    data = {}\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if \"=\" in line:\n",
    "                key, value = line.split(\"=\", 1)\n",
    "                data[key] = value\n",
    "    return data\n",
    "\n",
    "\n",
    "def merge_files(file_a, file_b, output_file):\n",
    "    data_a = read_file_to_dict(file_a)\n",
    "    data_b = read_file_to_dict(file_b)\n",
    "    \n",
    "    for key, value in data_b.items():\n",
    "        if key in data_a:\n",
    "            data_a[key] += \"/\" + value  # Nối thêm giá trị mới\n",
    "        else:\n",
    "            data_a[key] = value  # Thêm dòng mới\n",
    "    \n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as file:\n",
    "        for key, value in data_a.items():\n",
    "            file.write(f\"{key}={value}\\n\")\n",
    "\n",
    "\n",
    "merge_files(input_path_one, input_path_two, output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loại bỏ dòng trống"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã lọc xong, kết quả lưu vào ./final/VietPhrase_20250228_104100.txt\n"
     ]
    }
   ],
   "source": [
    "input_file = \"./final/VietPhrase_20250228_103111.txt\"   # Đổi thành tên file của bạn\n",
    "output_file = \"./final/VietPhrase_20250228_104100.txt\"\n",
    "output_file2 = \"./final/VietPhrase_20250228_104100_space.txt\"\n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as infile, open(output_file, \"w\", encoding=\"utf-8\") as outfile, open(output_file2, \"w\", encoding=\"utf-8\") as outfile2:\n",
    "    for line in infile:\n",
    "        parts = line.strip().split(\"=\")\n",
    "        if len(parts) == 2 and parts[1].strip():  # Kiểm tra vế phải có nội dung\n",
    "            outfile.write(line)\n",
    "        else:\n",
    "            outfile2.write(line)\n",
    "\n",
    "print(\"Đã lọc xong, kết quả lưu vào\", output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"./final/wordlist.10000.txt\"   # Đổi thành tên file của bạn\n",
    "output_file = \"./final/wordlist.10000_rs.txt\"\n",
    "\n",
    "def read_file_to_dict(filename, output_file):\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as file, open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "        for line in file:\n",
    "            line = line.strip() + \"=\" + line.strip() + \"\\n\"\n",
    "            outfile.write(line)\n",
    "\n",
    "read_file_to_dict(input_file, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "input_vp = './final/vpkhongloc_new28.txt'\n",
    "input_path_one = './final/VietPhrase_20250328_164933.txt'\n",
    "input_path_two = './final/VietPhrase_20250328_164933_new.txt'\n",
    "output_path = './final/VietPhrase_20250328_164933_merge.txt'\n",
    "\n",
    "regex3 = re.compile(r\"^第\\d+章?$\")\n",
    "\n",
    "def read_file_to_dict(filename, length=1, split_char=\"/\", join_char = \"/\"):\n",
    "    data = {}\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if \"=\" in line:\n",
    "                key, value = line.split(\"=\", 1)\n",
    "                if len(key) >= length:\n",
    "                    if key in data.keys() and not regex3.match(key):\n",
    "                        tempValue = data[key] + split_char + value\n",
    "                        data[key] = re.sub(r\"\\s*\\(.*?\\)\", \"\", join_char.join(dict.fromkeys(tempValue.split(split_char))))\n",
    "                    elif not regex3.match(key):\n",
    "                        data[key] = re.sub(r\"\\s*\\(.*?\\)\", \"\", join_char.join(value.split(split_char)))\n",
    "    return data\n",
    "\n",
    "\n",
    "def merge_files(file_a, file_b, file_vp, output_file):\n",
    "    const_split_char = \"/\"\n",
    "    data_vp = read_file_to_dict(file_vp, split_char=\"/\", join_char=\"/\")\n",
    "    data_a = read_file_to_dict(file_a, split_char=\"¦\", join_char=\"/\")\n",
    "    data_b = read_file_to_dict(file_b, split_char=\"/\", join_char=\"/\")\n",
    "\n",
    "    for key, value in data_b.items():\n",
    "        if key not in data_vp:\n",
    "            if key in data_a:\n",
    "                tempValue = data_a[key] + const_split_char + value\n",
    "                data_a[key] = const_split_char.join(dict.fromkeys(tempValue.split(const_split_char)))\n",
    "            else:\n",
    "                data_a[key] = value  # Thêm dòng mới\n",
    "\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as file:\n",
    "        for key, value in data_a.items():\n",
    "            file.write(f\"{key}={value}\\n\")\n",
    "\n",
    "\n",
    "merge_files(input_path_one, input_path_two, input_vp, output_path)\n",
    "# read_file_to_dict(input_path_one, split_char=\"¦\", join_char=\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Không khớp: 第1244章\n",
      "❌ Không khớp: 第1章\n",
      "✅ Khớp: 第99\n",
      "✅ Khớp: 第1000\n",
      "❌ Không khớp: 第500章\n",
      "✅ Khớp: 第42\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "pattern = r\"^第\\d+$\"\n",
    "\n",
    "# Kiểm tra mẫu regex\n",
    "texts = [\"第1244章\", \"第1章\", \"第99\", \"第1000\", \"第500章\", \"第42\"]\n",
    "for text in texts:\n",
    "    if re.match(pattern, text):\n",
    "        print(f\"✅ Khớp: {text}\")\n",
    "    else:\n",
    "        print(f\"❌ Không khớp: {text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'3', '9', '1', '6', '7', '2', '0', '4', '8', '5'}\n"
     ]
    }
   ],
   "source": [
    "input_file = \"./final/vpkhongloc_new19.txt\"\n",
    "output_file = \"./final/namecn.txt\"\n",
    "output_file_en = \"./final/name_en.txt\"\n",
    "output_file_vp = \"./final/vp.txt\"\n",
    "output_file_vp2 = \"./final/vp2.txt\"\n",
    "\n",
    "vietnamese_chars = set([\n",
    "    \"á\", \"à\", \"ả\", \"ã\", \"ạ\", \"ă\", \"ắ\", \"ằ\", \"ẳ\", \"ẵ\", \"ặ\",\n",
    "    \"â\", \"ấ\", \"ầ\", \"ẩ\", \"ẫ\", \"ậ\", \"é\", \"è\", \"ẻ\", \"ẽ\", \"ẹ\",\n",
    "    \"ê\", \"ế\", \"ề\", \"ể\", \"ễ\", \"ệ\", \"í\", \"ì\", \"ỉ\", \"ĩ\", \"ị\",\n",
    "    \"ó\", \"ò\", \"ỏ\", \"õ\", \"ọ\", \"ô\", \"ố\", \"ồ\", \"ổ\", \"ỗ\", \"ộ\",\n",
    "    \"ơ\", \"ớ\", \"ờ\", \"ở\", \"ỡ\", \"ợ\", \"ú\", \"ù\", \"ủ\", \"ũ\", \"ụ\",\n",
    "    \"ư\", \"ứ\", \"ừ\", \"ử\", \"ữ\", \"ự\", \"ý\", \"ỳ\", \"ỷ\", \"ỹ\", \"ỵ\"\n",
    "])\n",
    "\n",
    "number_set = {str(i) for i in range(10)}\n",
    "print(number_set)  # {'0', '1', '2', '3', '4', '5', '6', '7', '8', '9'}\n",
    "\n",
    "def has_vietnamese_chars(text):\n",
    "    return any(char in vietnamese_chars for char in text)\n",
    "\n",
    "def has_number(text):\n",
    "    return any(char in number_set for char in text)\n",
    "\n",
    "def nomanlizeFile(filename, output_file, output_file_en, output_file_vp2, output_file_vp):\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as file, \\\n",
    "         open(output_file, \"w\", encoding=\"utf-8\") as outfile, \\\n",
    "         open(output_file_en, \"w\", encoding=\"utf-8\") as outfile_en, \\\n",
    "         open(output_file_vp2, \"w\", encoding=\"utf-8\") as outfile_vp2, \\\n",
    "         open(output_file_vp, \"w\", encoding=\"utf-8\") as outfile_vp:\n",
    "        \n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if \"=\" in line:\n",
    "                key, value = line.split(\"=\", 1)\n",
    "                value = \"/\".join(list(dict.fromkeys(value.split(\"/\"))))  # Loại bỏ giá trị trùng lặp\n",
    "                arrValue = value.split(\"/\")\n",
    "\n",
    "                # Kiểm tra `value` có bị rỗng không trước khi truy cập `value[0]`\n",
    "                if len(arrValue) == 1 and value and value[0].isupper() and has_vietnamese_chars(value) and not \",\" in value and not has_number(value):\n",
    "                    outfile.write(key + \"=\" + value + \"\\n\")\n",
    "                elif len(arrValue) == 1 and value and value[0].isupper() and not has_vietnamese_chars(value) and not \",\" in value and not has_number(value):\n",
    "                    outfile_en.write(key + \"=\" + value + \"\\n\")\n",
    "                elif len(key) == 2:\n",
    "                    outfile_vp2.write(key + \"=\" + value + \"\\n\")\n",
    "                else:\n",
    "                    outfile_vp.write(key + \"=\" + value + \"\\n\")\n",
    "\n",
    "nomanlizeFile(input_file, output_file, output_file_en, output_file_vp2, output_file_vp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "是我们_是你的们_是你_你们的_自己_这_是你们_你们_他_此_你_那的_我的_那_我_是我_其他的_其他_是我们的_我们_自己的_他的_是你的_是他们的_这的_是我的_我们的_他们的_你的_是他们_他们\n",
      "的他们_的是我们_的是我_的他_的你_的自己_的那_的你们_的是他们_的是你们_的_的人_的我们_的是你_的这_的我_的其他\n"
     ]
    }
   ],
   "source": [
    "input_file = \"./final/vpkhongloc_new25.txt\"\n",
    "output_file_3 = \"./final/vpkhongloc_new25.txt\"\n",
    "\n",
    "other_words = set([\n",
    "    \"·\",\n",
    "    \",\",\n",
    "    \"-\",\n",
    "    \".\",\n",
    "    \"?\",\n",
    "    \"!\"\n",
    "])\n",
    "\n",
    "start_words = set([\n",
    "    \"此\",\n",
    "    \"他\",\n",
    "    \"你\",\n",
    "    \"我\",\n",
    "    \"这\",\n",
    "    \"那\",\n",
    "    \"你们\",\n",
    "    \"其他\",\n",
    "    \"他们\",\n",
    "    \"我们\",\n",
    "    \"是我\",\n",
    "    \"是你\",\n",
    "    \"自己\",\n",
    "    \"是他们\",\n",
    "    \"是我们\",\n",
    "    \"是你们\",\n",
    "    \"他的\",\n",
    "    \"你的\",\n",
    "    \"我的\",\n",
    "    \"这的\",\n",
    "    \"那的\",\n",
    "    \"你们的\",\n",
    "    \"其他的\",\n",
    "    \"他们的\",\n",
    "    \"我们的\",\n",
    "    \"是我的\",\n",
    "    \"是你的\",\n",
    "    \"自己的\",\n",
    "    \"是他们的\",\n",
    "    \"是我们的\",\n",
    "    \"是你的们\"\n",
    "])\n",
    "\n",
    "start_words_join = \"_\".join(start_words)\n",
    "print(start_words_join)\n",
    "\n",
    "output_file_1 = f\"./final/{start_words_join}_remove.txt\"\n",
    "\n",
    "end_words = set([\n",
    "    \"的人\",\n",
    "    \"的自己\",\n",
    "    \"的他\",\n",
    "    \"的你\",\n",
    "    \"的我\",\n",
    "    \"的这\",\n",
    "    \"的那\",\n",
    "    \"的你们\",\n",
    "    \"的其他\",\n",
    "    \"的他们\",\n",
    "    \"的我们\",\n",
    "    \"的是我\",\n",
    "    \"的是你\",\n",
    "    \"的自己\",\n",
    "    \"的是他们\",\n",
    "    \"的是我们\",\n",
    "    \"的是你们\",\n",
    "])\n",
    "\n",
    "end_words_join = \"_\".join(end_words)\n",
    "print(end_words_join)\n",
    "\n",
    "output_file_2 = f\"./final/{end_words_join}_end_remove.txt\"\n",
    "\n",
    "\n",
    "def nomanlizeFile(filename, output_file_1, output_file_2, output_file_3):\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as file, \\\n",
    "         open(output_file_1, \"w\", encoding=\"utf-8\") as outfile1, \\\n",
    "         open(output_file_3, \"w\", encoding=\"utf-8\") as outfile3, \\\n",
    "         open(output_file_2, \"w\", encoding=\"utf-8\") as outfile2:\n",
    "        \n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if \"=\" in line:\n",
    "                key, value = line.split(\"=\", 1)\n",
    "                arrValue = list(dict.fromkeys(value.split(\"/\")))\n",
    "                value = \"/\".join(arrValue)\n",
    "                if any(key.startswith(item) for item in start_words) and not key in start_words and not any(item in key for item in other_words):\n",
    "                    outfile1.write(f\"{key}={value}\\n\")\n",
    "                elif any(key.endswith(item) for item in end_words) and not key in end_words and not any(item in key for item in other_words):\n",
    "                    outfile2.write(f\"{key}={value}\\n\")\n",
    "                else:\n",
    "                    outfile3.write(f\"{key}={value}\\n\")\n",
    "                        \n",
    "\n",
    "nomanlizeFile(input_file, output_file_1, output_file_2, output_file_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"./final/vpkhongloc_new25.txt\"\n",
    "output_file_3 = \"./final/vpkhongloc_new26.txt\"\n",
    "\n",
    "def read_file_to_dict(filename, length=1, split_char=\"/\", join_char = \"/\"):\n",
    "    data = {}\n",
    "    with open(filename, \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            line = line.strip()\n",
    "            if \"=\" in line:\n",
    "                key, value = line.split(\"=\", 1)\n",
    "                if len(key) >= length:\n",
    "                    if key in data.keys():\n",
    "                        tempValue = data[key] + split_char + value\n",
    "                        data[key] = re.sub(r\"\\s*\\(.*?\\)\", \"\", join_char.join(dict.fromkeys(tempValue.split(split_char))))\n",
    "                    else:\n",
    "                        data[key] = re.sub(r\"\\s*\\(.*?\\)\", \"\", join_char.join(value.split(split_char)))\n",
    "    return data\n",
    "\n",
    "def nomanlizeFile(filename, output_file):\n",
    "    dictData = read_file_to_dict(filename, split_char=\"/\", join_char=\"/\")\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as outfile:\n",
    "        for key, value in dictData.items():\n",
    "            if key.endswith(\"的\") and key[:-1] in dictData.keys() and len(key) > 3:\n",
    "                tempValue = \"/\".join(list(dict.fromkeys(f\"{dictData[key[:-1]]}/{value}\".split(\"/\"))))\n",
    "                outfile.write(f\"{key}={tempValue}\\n\")\n",
    "            else:\n",
    "                outfile.write(f\"{key}={value}\\n\")\n",
    "                        \n",
    "\n",
    "nomanlizeFile(input_file, output_file_3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
